{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name** : Bodhisatya Ghosh \\\n",
    "**Class** : CSE DS \\\n",
    "**UID** : 2021700026 \\\n",
    "**Subject** : NLP \\\n",
    "**Experiment number** : 5 \\\n",
    "\\\n",
    "**Aim**:\n",
    "Print emission & transition matrix \\\n",
    "Calculate POS tags for a given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Ways for tagging parts of speech:\n",
    "\n",
    "   a. Rule-based tagging: Utilizes predefined grammatical rules to assign parts of speech based on word patterns and context.\n",
    "   \n",
    "   b. Dictionary-based tagging: Matches words against a pre-built dictionary that includes information about the part of speech of each word.\n",
    "   \n",
    "   c. Probabilistic tagging: Uses statistical models to determine the likelihood of a word belonging to a specific part of speech based on training data.\n",
    "\n",
    "   d. Machine learning-based tagging: Employs machine learning algorithms, such as Hidden Markov Models (HMMs) or Conditional Random Fields (CRFs), trained on annotated corpora to predict parts of speech.\n",
    "\n",
    "2. Finding the most probable sequence of POS tags:\n",
    "\n",
    "   a. Hidden Markov Models (HMMs): Use the Viterbi algorithm to find the most probable sequence of POS tags based on the emission and transition probabilities.\n",
    "   \n",
    "   b. Conditional Random Fields (CRFs): Optimize a conditional probability model that considers the entire sequence, taking into account both local and global context.\n",
    "\n",
    "3. Markov chain vs. Markov model:\n",
    "\n",
    "   - Markov Chain: A mathematical model representing a sequence of events where the probability of transitioning to any particular state depends solely on the current state. It has discrete states and transition probabilities.\n",
    "   \n",
    "   - Markov Model: A broader term that encompasses various mathematical models, including Markov Chains. Markov Models can refer to systems with both discrete and continuous states, and they may have additional parameters beyond transition probabilities.\n",
    "\n",
    "4. Identifying whether a system follows a Markov Process:\n",
    "\n",
    "   - If a system exhibits the Markov property, meaning the future state depends only on the present state and not on the sequence of events leading to the present state, it can be considered a Markov Process. This property can be assessed by analyzing the conditional probability distribution of future states given the current state.\n",
    "\n",
    "5. Use of Markov Chains in text generation algorithms:\n",
    "\n",
    "   - Markov Chains can model the transition probabilities between words or characters in a text. By analyzing a training corpus, the probabilities of transitioning from one word to another can be learned.\n",
    "   \n",
    "   - In text generation, a Markov Chain can be used to predict the next word or sequence of words based on the current state (previous words). This allows for the generation of coherent and contextually relevant text, making Markov Chains a simple yet effective tool for text generation algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_hmm(tagged_corpus):\n",
    "    states = set()\n",
    "    emissions = set()\n",
    "    transitions = {}\n",
    "\n",
    "    for sentence in tagged_corpus:\n",
    "        prev_state = None\n",
    "        for word, tag in sentence:\n",
    "            states.add(tag)\n",
    "            emissions.add(word)\n",
    "\n",
    "            if prev_state is not None:\n",
    "                if (prev_state, tag) in transitions:\n",
    "                    transitions[(prev_state, tag)] += 1\n",
    "                else:\n",
    "                    transitions[(prev_state, tag)] = 1\n",
    "            prev_state = tag\n",
    "\n",
    "    # transition counts to get probabilities\n",
    "    transition_matrix = np.zeros((len(states), len(states)))\n",
    "    for (i, state1) in enumerate(states):\n",
    "        for (j, state2) in enumerate(states):\n",
    "            transition_matrix[i, j] = transitions.get((state1, state2), 0)\n",
    "\n",
    "    transition_matrix /= transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # emission probabilities\n",
    "    emission_matrix = np.zeros((len(states), len(emissions)))\n",
    "    for sentence in tagged_corpus:\n",
    "        for word, tag in sentence:\n",
    "            emission_matrix[list(states).index(tag), list(emissions).index(word)] += 1\n",
    "\n",
    "    emission_matrix /= emission_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    return list(states), list(emissions), transition_matrix, emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentence, states, emissions, emission_matrix):\n",
    "    tags = []\n",
    "\n",
    "    for word in sentence:\n",
    "        if word not in emissions:\n",
    "            #Using the first tag as default tag\n",
    "            tags.append(states[0])\n",
    "        else:\n",
    "            word_index = emissions.index(word)\n",
    "            state_index = np.argmax(emission_matrix[:, word_index])\n",
    "            tags.append(states[state_index])\n",
    "\n",
    "    return list(zip(sentence, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission Matrix:\n",
      "          peppers sells of A She is pickled The seashore brown a could picked the much mat by wood jumps seashells fox cat woodchuck would over on if dog quick peck Piper chuck How lazy Peter\n",
      "IN   [0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.\n",
      " 0.  0.  0.  0.  0.  0.  0.2 0.2 0.2 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "VBZ  [0.         0.33333333 0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "NNP  [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5]\n",
      "VB   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "VBD  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "NN   [0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.1 0.  0.2\n",
      " 0.  0.  0.1 0.1 0.2 0.  0.  0.  0.  0.1 0.  0.1 0.  0.  0.  0.  0. ]\n",
      "NNS  [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "MD   [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "DT   [0.    0.    0.    0.125 0.    0.    0.    0.125 0.    0.    0.375 0.\n",
      " 0.    0.375 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "PRP  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "JJ   [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.\n",
      " 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.25 0.   0.   0.   0.   0.25 0.  ]\n",
      "VBN  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "WRB  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "Transition Matrix:\n",
      "          IN VBZ NNP VB VBD NN NNS MD DT PRP JJ VBN WRB\n",
      "IN   [0.  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.  0.2 0. ]\n",
      "VBZ  [0.66666667 0.         0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "NNP  [0.  0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "VB   [0.5 0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0. ]\n",
      "VBD  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "NN   [0.16666667 0.33333333 0.         0.16666667 0.         0.\n",
      " 0.         0.33333333 0.         0.         0.         0.\n",
      " 0.        ]\n",
      "NNS  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "MD   [0.  0.  0.  0.5 0.  0.  0.  0.  0.5 0.  0.  0.  0. ]\n",
      "DT   [0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.   0.  ]\n",
      "PRP  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "JJ   [0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.25 0.   0.  ]\n",
      "VBN  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "WRB  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "POS Tagging Result:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tagged_corpus = [\n",
    "    [(\"The\", \"DT\"), (\"cat\", \"NN\"), (\"is\", \"VBZ\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")],\n",
    "    [(\"A\", \"DT\"), (\"quick\", \"JJ\"), (\"brown\", \"JJ\"), (\"fox\", \"NN\"), (\"jumps\", \"VBZ\"), (\"over\", \"IN\"), (\"the\", \"DT\"), (\"lazy\", \"JJ\"), (\"dog\", \"NN\")],\n",
    "    [(\"She\", \"PRP\"), (\"sells\", \"VBZ\"), (\"seashells\", \"NNS\"), (\"by\", \"IN\"), (\"the\", \"DT\"), (\"seashore\", \"NN\")],\n",
    "    [(\"Peter\", \"NNP\"), (\"Piper\", \"NNP\"), (\"picked\", \"VBD\"), (\"a\", \"DT\"), (\"peck\", \"NN\"), (\"of\", \"IN\"), (\"pickled\", \"VBN\"), (\"peppers\", \"NNS\")],\n",
    "    [(\"How\", \"WRB\"), (\"much\", \"JJ\"), (\"wood\", \"NN\"), (\"would\", \"MD\"), (\"a\", \"DT\"), (\"woodchuck\", \"NN\"), (\"chuck\", \"VB\"), (\"if\", \"IN\"), (\"a\", \"DT\"), (\"woodchuck\", \"NN\"), (\"could\", \"MD\"), (\"chuck\", \"VB\"), (\"wood\", \"NN\")],\n",
    "]\n",
    "\n",
    "states, emissions, transition_matrix, emission_matrix = train_hmm(tagged_corpus)\n",
    "\n",
    "# Print the emission matrix\n",
    "print(\"Emission Matrix:\")\n",
    "print(\"          \" + \" \".join(emissions))\n",
    "for i, row in enumerate(emission_matrix):\n",
    "    print(f\"{states[i]:<4} {row}\")\n",
    "\n",
    "# Print the transition matrix \n",
    "print(\"\\nTransition Matrix:\")\n",
    "print(\"          \" + \" \".join(states))\n",
    "for i, row in enumerate(transition_matrix):\n",
    "    print(f\"{states[i]:<4} {row}\")\n",
    "\n",
    "example_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "example_sentence = example_sentence.split()\n",
    "\n",
    "result = pos_tag(example_sentence, states, emissions, emission_matrix)\n",
    "\n",
    "\n",
    "print(\"\\nPOS Tagging Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

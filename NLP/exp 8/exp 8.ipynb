{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Bodhisatya Ghosh <br/>\n",
    "**UID:** 2021700026 <br/>\n",
    "**Branch:** CSE DS <br/>\n",
    "**Experiment:** 8 <br/>\n",
    "**Batch**: A <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constituency parsing is an important step in natural language processing and is used in a wide range of applications, such as natural language understanding, machine translation, and text summarization.\n",
    "\n",
    "Constituency parsing is different from dependency parsing, which aims to identify the syntactic relations between words in a sentence. Constituency parsing focuses on the hierarchical structure of the sentence, while dependency parsing focuses on the linear structure of the sentence. Both techniques have their own advantages and can be used together to better understand a sentence.\n",
    "\n",
    "Some challenges in Constituency Parsing are long-distance dependencies, syntactic ambiguity, and the handling of idiomatic expressions, which makes the parsing process more complex.\n",
    "\n",
    "Applications of Constituency Parsing\n",
    "Constituency parsing is a process of identifying the constituents (noun phrases, verbs, clauses, etc.) in a sentence and grouping them into a tree-like structure that represents the grammatical relationships among them.\n",
    "\n",
    "#### The following are some of the applications of constituency parsing:\n",
    "\n",
    "* Natural Language Processing (NLP) – It is used in various NLP tasks such as text summarization, machine translation, question answering, and text classification.\n",
    "* Information Retrieval – It is used to extract information from large corpora and to index it for efficient retrieval.\n",
    "* Text-to-Speech – It helps in generating human-like speech by understanding the grammar and structure of the text.\n",
    "* Sentiment Analysis – It helps in determining the sentiment of a text by identifying positive, negative, or neutral sentiments in the constituents.\n",
    "* Text-based Games and Chatbots – It helps in generating more human-like responses in text-based games and chatbots.\n",
    "* Text Summarization – It is used to summarize large texts by identifying the most important constituents and representing them in a compact form.\n",
    "* Text Classification – It is used to classify text into predefined categories by analyzing the constituent structure and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 09:23:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb743f592ff640cd9af7fbce4c381f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 09:23:49 INFO: Downloaded file to C:\\Users\\Rommel\\stanza_resources\\resources.json\n",
      "2024-04-26 09:23:49 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-04-26 09:23:49 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2024-04-26 09:23:49 INFO: Using device: cpu\n",
      "2024-04-26 09:23:49 INFO: Loading: tokenize\n",
      "2024-04-26 09:23:49 INFO: Loading: mwt\n",
      "2024-04-26 09:23:49 INFO: Loading: pos\n",
      "2024-04-26 09:23:49 INFO: Loading: constituency\n",
      "2024-04-26 09:23:50 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ROOT (S (NP (DT the) (NN dog)) (VP (VBD chased) (NP (DT the) (NN cat))) (. .)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(ROOT (S (NP (DT a) (NN cat)) (VP (VBD chased) (NP (DT the) (NN ball))) (. .)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(ROOT (S (NP (DT the) (NN dog)) (VP (VBD chased) (NP (DT the) (NN ball)) (PP (IN with) (NP (DT a) (NN stick)))) (. .)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
    "doc = nlp('the dog chased the cat. a cat chased the ball. the dog chased the ball with a stick.')\n",
    "for sentence in doc.sentences:\n",
    "    display(sentence.constituency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the dog chased the cat\n",
      "(S (NP (DT the) (NN dog)) (VP (VBD chased) (NP (DT the) (NN cat))))\n",
      "\n",
      "\n",
      "Sentence: a cat chased the ball\n",
      "(S (NP (DT a) (NN cat)) (VP (VBD chased) (NP (DT the) (NN ball))))\n",
      "\n",
      "\n",
      "Sentence: the dog chased the ball with a stick\n",
      "(S\n",
      "  (NP (DT the) (NN dog))\n",
      "  (VP\n",
      "    (VP (VBD chased) (NP (DT the) (NN ball)))\n",
      "    (PP (P with) (NP (DT a) (NN stick)))))\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (DT the) (NN dog))\n",
      "  (VP\n",
      "    (VBD chased)\n",
      "    (NP (NP (DT the) (NN ball)) (PP (P with) (NP (DT a) (NN stick))))))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> DT NN | NP PP\n",
    "    VP -> VBD NP | VP PP\n",
    "    PP -> P NP\n",
    "    DT -> 'the' | 'a'\n",
    "    NN -> 'dog' | 'cat' | 'ball' | 'bone' | 'park' | 'stick'\n",
    "    VBD -> 'chased' | 'ate'\n",
    "    P -> 'with' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "sentences = [\n",
    "    \"the dog chased the cat\",\n",
    "    \"a cat chased the ball\",\n",
    "    \"the dog chased the ball with a stick\",\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"Sentence:\", sentence)\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    parser = nltk.ChartParser(grammar)\n",
    "    trees = list(parser.parse(tokens))\n",
    "    for tree in trees:\n",
    "        print(tree)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name** : Bodhisatya Ghosh \\\n",
    "**Class** : CSE DS \\\n",
    "**UID** : 2021700026 \\\n",
    "**Subject** : NLP \\\n",
    "**Experiment number** : 3 \\\n",
    "\\\n",
    "**Aim**:\n",
    "1. Calculate bigrams from a given corpus , display bigram probability table and calculate probability of a sentence.\n",
    "2. To apply add-one smoothing on sparse bigram table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "allText = pd.read_csv('../exp 2/reviews.csv',usecols=['review'])\n",
    "corpus = allText['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perform preprocessing. (Covert data to lowercase, and remove punctuation marks and stop words to remove noise. Use the eos tag to mark the beginning and end of the sentence.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation and everything else except letters and numbers\n",
    "corpus = re.sub(r\"[^A-Za-z0-9.']\",\" \",corpus)\n",
    "corpus = re.sub(r\"\\s+\",\" \",corpus)\n",
    "\n",
    "#Switch to lower case\n",
    "corpus = corpus.lower()\n",
    "\n",
    "corpus = sent_tokenize(corpus)\n",
    "corpus = [word_tokenize(sentence) for sentence in corpus]\n",
    "\n",
    "corpus = [[word for word in sentence] for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "corpusFinal = []\n",
    "for sentence in corpus:\n",
    "    #Convert to string to tokenize and clean\n",
    "    sentenceString = \" \".join(sentence)\n",
    "    sentenceString = re.sub(r\"[.']\",\" \",sentenceString)\n",
    "    sentenceString = re.sub(r\"\\s+\",\" \",sentenceString)\n",
    "    \n",
    "    #tokenize sentence, filter stopwords and add eos tag\n",
    "    word_tokens = word_tokenize(sentenceString)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [\"<sos>\"] + filtered_sentence + [\"<eos>\"]\n",
    "\n",
    "    corpusFinal.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', 'one'),\n",
       " ('one', 'reviewers'),\n",
       " ('reviewers', 'mentioned'),\n",
       " ('mentioned', 'watching'),\n",
       " ('watching', '1'),\n",
       " ('1', 'oz'),\n",
       " ('oz', 'episode'),\n",
       " ('episode', 'hooked'),\n",
       " ('hooked', '<eos>')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramsList = []\n",
    "for sentence in corpusFinal:\n",
    "    # token = word_tokenize(\" \".join(sentence))\n",
    "    bigramsList.append(list(bigrams(sentence)))\n",
    "bigramsList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate frequency of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('<sos>', 'br'): 3, ('br', 'br'): 3, ('violence', '<eos>'): 2, ('<sos>', 'one'): 1, ('one', 'reviewers'): 1, ('reviewers', 'mentioned'): 1, ('mentioned', 'watching'): 1, ('watching', '1'): 1, ('1', 'oz'): 1, ('oz', 'episode'): 1, ...})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_freq = FreqDist([bigram for sentence_bigram in bigramsList for bigram in sentence_bigram])\n",
    "bigram_freq = dict(bigram_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate bi-gram probability table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<sos>', 'br'): 0.016042780748663103,\n",
       " ('br', 'br'): 0.016042780748663103,\n",
       " ('violence', '<eos>'): 0.0106951871657754,\n",
       " ('<sos>', 'one'): 0.0053475935828877,\n",
       " ('one', 'reviewers'): 0.0053475935828877,\n",
       " ('reviewers', 'mentioned'): 0.0053475935828877,\n",
       " ('mentioned', 'watching'): 0.0053475935828877,\n",
       " ('watching', '1'): 0.0053475935828877,\n",
       " ('1', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'episode'): 0.0053475935828877,\n",
       " ('episode', 'hooked'): 0.0053475935828877,\n",
       " ('hooked', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'right'): 0.0053475935828877,\n",
       " ('right', 'exactly'): 0.0053475935828877,\n",
       " ('exactly', 'happened'): 0.0053475935828877,\n",
       " ('happened', '<eos>'): 0.0053475935828877,\n",
       " ('br', 'first'): 0.0053475935828877,\n",
       " ('first', 'thing'): 0.0053475935828877,\n",
       " ('thing', 'struck'): 0.0053475935828877,\n",
       " ('struck', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'brutality'): 0.0053475935828877,\n",
       " ('brutality', 'unflinching'): 0.0053475935828877,\n",
       " ('unflinching', 'scenes'): 0.0053475935828877,\n",
       " ('scenes', 'violence'): 0.0053475935828877,\n",
       " ('violence', 'set'): 0.0053475935828877,\n",
       " ('set', 'right'): 0.0053475935828877,\n",
       " ('right', 'word'): 0.0053475935828877,\n",
       " ('word', 'go'): 0.0053475935828877,\n",
       " ('go', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'trust'): 0.0053475935828877,\n",
       " ('trust', 'show'): 0.0053475935828877,\n",
       " ('show', 'faint'): 0.0053475935828877,\n",
       " ('faint', 'hearted'): 0.0053475935828877,\n",
       " ('hearted', 'timid'): 0.0053475935828877,\n",
       " ('timid', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'show'): 0.0053475935828877,\n",
       " ('show', 'pulls'): 0.0053475935828877,\n",
       " ('pulls', 'punches'): 0.0053475935828877,\n",
       " ('punches', 'regards'): 0.0053475935828877,\n",
       " ('regards', 'drugs'): 0.0053475935828877,\n",
       " ('drugs', 'sex'): 0.0053475935828877,\n",
       " ('sex', 'violence'): 0.0053475935828877,\n",
       " ('<sos>', 'hardcore'): 0.0053475935828877,\n",
       " ('hardcore', 'classic'): 0.0053475935828877,\n",
       " ('classic', 'use'): 0.0053475935828877,\n",
       " ('use', 'word'): 0.0053475935828877,\n",
       " ('word', '<eos>'): 0.0053475935828877,\n",
       " ('br', 'called'): 0.0053475935828877,\n",
       " ('called', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'nickname'): 0.0053475935828877,\n",
       " ('nickname', 'given'): 0.0053475935828877,\n",
       " ('given', 'oswald'): 0.0053475935828877,\n",
       " ('oswald', 'maximum'): 0.0053475935828877,\n",
       " ('maximum', 'security'): 0.0053475935828877,\n",
       " ('security', 'state'): 0.0053475935828877,\n",
       " ('state', 'penitentary'): 0.0053475935828877,\n",
       " ('penitentary', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'focuses'): 0.0053475935828877,\n",
       " ('focuses', 'mainly'): 0.0053475935828877,\n",
       " ('mainly', 'emerald'): 0.0053475935828877,\n",
       " ('emerald', 'city'): 0.0053475935828877,\n",
       " ('city', 'experimental'): 0.0053475935828877,\n",
       " ('experimental', 'section'): 0.0053475935828877,\n",
       " ('section', 'prison'): 0.0053475935828877,\n",
       " ('prison', 'cells'): 0.0053475935828877,\n",
       " ('cells', 'glass'): 0.0053475935828877,\n",
       " ('glass', 'fronts'): 0.0053475935828877,\n",
       " ('fronts', 'face'): 0.0053475935828877,\n",
       " ('face', 'inwards'): 0.0053475935828877,\n",
       " ('inwards', 'privacy'): 0.0053475935828877,\n",
       " ('privacy', 'high'): 0.0053475935828877,\n",
       " ('high', 'agenda'): 0.0053475935828877,\n",
       " ('agenda', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'em'): 0.0053475935828877,\n",
       " ('em', 'city'): 0.0053475935828877,\n",
       " ('city', 'home'): 0.0053475935828877,\n",
       " ('home', 'many'): 0.0053475935828877,\n",
       " ('many', 'aryans'): 0.0053475935828877,\n",
       " ('aryans', 'muslims'): 0.0053475935828877,\n",
       " ('muslims', 'gangstas'): 0.0053475935828877,\n",
       " ('gangstas', 'latinos'): 0.0053475935828877,\n",
       " ('latinos', 'christians'): 0.0053475935828877,\n",
       " ('christians', 'italians'): 0.0053475935828877,\n",
       " ('italians', 'irish'): 0.0053475935828877,\n",
       " ('irish', 'scuffles'): 0.0053475935828877,\n",
       " ('scuffles', 'death'): 0.0053475935828877,\n",
       " ('death', 'stares'): 0.0053475935828877,\n",
       " ('stares', 'dodgy'): 0.0053475935828877,\n",
       " ('dodgy', 'dealings'): 0.0053475935828877,\n",
       " ('dealings', 'shady'): 0.0053475935828877,\n",
       " ('shady', 'agreements'): 0.0053475935828877,\n",
       " ('agreements', 'never'): 0.0053475935828877,\n",
       " ('never', 'far'): 0.0053475935828877,\n",
       " ('far', 'away'): 0.0053475935828877,\n",
       " ('away', '<eos>'): 0.0053475935828877,\n",
       " ('br', 'would'): 0.0053475935828877,\n",
       " ('would', 'say'): 0.0053475935828877,\n",
       " ('say', 'main'): 0.0053475935828877,\n",
       " ('main', 'appeal'): 0.0053475935828877,\n",
       " ('appeal', 'show'): 0.0053475935828877,\n",
       " ('show', 'due'): 0.0053475935828877,\n",
       " ('due', 'fact'): 0.0053475935828877,\n",
       " ('fact', 'goes'): 0.0053475935828877,\n",
       " ('goes', 'shows'): 0.0053475935828877,\n",
       " ('shows', 'would'): 0.0053475935828877,\n",
       " ('would', 'n'): 0.0053475935828877,\n",
       " ('n', 'dare'): 0.0053475935828877,\n",
       " ('dare', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'forget'): 0.0053475935828877,\n",
       " ('forget', 'pretty'): 0.0053475935828877,\n",
       " ('pretty', 'pictures'): 0.0053475935828877,\n",
       " ('pictures', 'painted'): 0.0053475935828877,\n",
       " ('painted', 'mainstream'): 0.0053475935828877,\n",
       " ('mainstream', 'audiences'): 0.0053475935828877,\n",
       " ('audiences', 'forget'): 0.0053475935828877,\n",
       " ('forget', 'charm'): 0.0053475935828877,\n",
       " ('charm', 'forget'): 0.0053475935828877,\n",
       " ('forget', 'romance'): 0.0053475935828877,\n",
       " ('romance', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'n'): 0.0053475935828877,\n",
       " ('n', 'mess'): 0.0053475935828877,\n",
       " ('mess', 'around'): 0.0053475935828877,\n",
       " ('around', '<eos>'): 0.0053475935828877,\n",
       " ('<sos>', 'first'): 0.0053475935828877,\n",
       " ('first', 'episode'): 0.0053475935828877,\n",
       " ('episode', 'ever'): 0.0053475935828877,\n",
       " ('ever', 'saw'): 0.0053475935828877,\n",
       " ('saw', 'struck'): 0.0053475935828877,\n",
       " ('struck', 'nasty'): 0.0053475935828877,\n",
       " ('nasty', 'surreal'): 0.0053475935828877,\n",
       " ('surreal', 'could'): 0.0053475935828877,\n",
       " ('could', 'n'): 0.0053475935828877,\n",
       " ('n', 'say'): 0.0053475935828877,\n",
       " ('say', 'ready'): 0.0053475935828877,\n",
       " ('ready', 'watched'): 0.0053475935828877,\n",
       " ('watched', 'developed'): 0.0053475935828877,\n",
       " ('developed', 'taste'): 0.0053475935828877,\n",
       " ('taste', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'got'): 0.0053475935828877,\n",
       " ('got', 'accustomed'): 0.0053475935828877,\n",
       " ('accustomed', 'high'): 0.0053475935828877,\n",
       " ('high', 'levels'): 0.0053475935828877,\n",
       " ('levels', 'graphic'): 0.0053475935828877,\n",
       " ('graphic', 'violence'): 0.0053475935828877,\n",
       " ('<sos>', 'violence'): 0.0053475935828877,\n",
       " ('violence', 'injustice'): 0.0053475935828877,\n",
       " ('injustice', 'crooked'): 0.0053475935828877,\n",
       " ('crooked', 'guards'): 0.0053475935828877,\n",
       " ('guards', 'sold'): 0.0053475935828877,\n",
       " ('sold', 'nickel'): 0.0053475935828877,\n",
       " ('nickel', 'inmates'): 0.0053475935828877,\n",
       " ('inmates', 'kill'): 0.0053475935828877,\n",
       " ('kill', 'order'): 0.0053475935828877,\n",
       " ('order', 'get'): 0.0053475935828877,\n",
       " ('get', 'away'): 0.0053475935828877,\n",
       " ('away', 'well'): 0.0053475935828877,\n",
       " ('well', 'mannered'): 0.0053475935828877,\n",
       " ('mannered', 'middle'): 0.0053475935828877,\n",
       " ('middle', 'class'): 0.0053475935828877,\n",
       " ('class', 'inmates'): 0.0053475935828877,\n",
       " ('inmates', 'turned'): 0.0053475935828877,\n",
       " ('turned', 'prison'): 0.0053475935828877,\n",
       " ('prison', 'bitches'): 0.0053475935828877,\n",
       " ('bitches', 'due'): 0.0053475935828877,\n",
       " ('due', 'lack'): 0.0053475935828877,\n",
       " ('lack', 'street'): 0.0053475935828877,\n",
       " ('street', 'skills'): 0.0053475935828877,\n",
       " ('skills', 'prison'): 0.0053475935828877,\n",
       " ('prison', 'experience'): 0.0053475935828877,\n",
       " ('experience', 'watching'): 0.0053475935828877,\n",
       " ('watching', 'oz'): 0.0053475935828877,\n",
       " ('oz', 'may'): 0.0053475935828877,\n",
       " ('may', 'become'): 0.0053475935828877,\n",
       " ('become', 'comfortable'): 0.0053475935828877,\n",
       " ('comfortable', 'uncomfortable'): 0.0053475935828877,\n",
       " ('uncomfortable', 'viewing'): 0.0053475935828877,\n",
       " ('viewing', 'thats'): 0.0053475935828877,\n",
       " ('thats', 'get'): 0.0053475935828877,\n",
       " ('get', 'touch'): 0.0053475935828877,\n",
       " ('touch', 'darker'): 0.0053475935828877,\n",
       " ('darker', 'side'): 0.0053475935828877,\n",
       " ('side', '<eos>'): 0.0053475935828877}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_prob = {}\n",
    "total_bigrams = 0\n",
    "\n",
    "for bigram in bigram_freq:\n",
    "    total_bigrams += bigram_freq[bigram]\n",
    "for bigram in bigram_freq:\n",
    "    bigram_prob[bigram] = bigram_freq[bigram]/total_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Bodhisatya Ghosh <br/>\n",
    "**UID:** 2021700026 <br/>\n",
    "**Branch:** CSE DS <br/>\n",
    "**Experiment:** 7 <br/>\n",
    "**Batch**: A <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim : Chunking and Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory: \n",
    "* Q1. What is chunking?\n",
    "\n",
    "-> Chunking is a process of extracting phrases from unstructured text, which\n",
    "means analysing a sentence to identify the constituents(Noun Groups, Verbs, verb\n",
    "groups, etc.) However, it does not specify their internal structure, nor their role in\n",
    "the main sentence. It works on top of POS tagging. It uses POS-tags as input and\n",
    "provides chunks as output. In short, Chunking means grouping of words/tokens\n",
    "into chunks. Chunking can break sentences into phrases that are more useful than\n",
    "individual words and yield meaningful results. Chunking is very important when\n",
    "you want to extract information from text such as locations, person names.\n",
    "Groups of words make up phrases and there are five major categories.\n",
    "• Noun Phrase(NP)\n",
    "• Verb phrase (VP)\n",
    "• Adjective phrase (ADJP)\n",
    "• Adverb phrase (ADVP)\n",
    "• Prepositional phrase (PP)\n",
    "For example, the sentence 'He reckons the current account deficit will narrow to\n",
    "only 1.8 billion in September.' can be divided as follows: [NP He ] [VP reckons ]\n",
    "[NP the current account deficit ] [VP will narrow ] [PP to ] [NP only 1.8 billion ]\n",
    "[PP in ] [NP September ]\n",
    "\n",
    "* Q2. Explain Named Entity Recognition.\n",
    "\n",
    "-> Named Entity Recognition (NER) is a natural language processing (NLP) task\n",
    "that involves identifying and classifying named entities within a body of text.\n",
    "Named entities are typically real-world objects that have names, such as persons,\n",
    "organizations, locations, dates, numerical expressions, and more. The goal of\n",
    "Named Entity Recognition is to locate and classify these entities into predefined\n",
    "categories. Named Entity Recognition is a crucial component in various NLP\n",
    "applications, including information extraction, question answering, document\n",
    "summarization, and more. It helps in understanding the structure and semantics of\n",
    "text data by identifying important entities and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tree import Tree\n",
    "from tabulate import tabulate\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Rommel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Rommel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"A natural language processing program always includes cleaning the Data before moving on. With John Grinder, he founded the neuro-linguistic programming (NLP) approach to psychotherapy in the 1970s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "        NP:{<DT|JJ|NN.*>+}\n",
    "        PP:{<IN><NP>}\n",
    "        VP:{<VB.*><NP|PP|CLAUSE>+$}\n",
    "        ADJP:{<JJ.*><PP|CLAUSE>*}\n",
    "        ADVP:{<RB.*><PP|CLAUSE>*}\n",
    "        CLAUSE:{<NP><VP>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokenized)\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "    parsed = chunk_parser.parse(tagged)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks(parsed_sentence):\n",
    "    chunks = []\n",
    "    for subtree in parsed_sentence:\n",
    "        if type(subtree) == Tree:\n",
    "            label = subtree.label()\n",
    "            phrase = \" \".join([word for word, tag in subtree.leaves()])\n",
    "            chunks.append((label, phrase))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------------------+\n",
      "| Chunk type   | Chunk Phrase                          |\n",
      "+==============+=======================================+\n",
      "| NP           | A natural language processing program |\n",
      "+--------------+---------------------------------------+\n",
      "| ADVP         | always                                |\n",
      "+--------------+---------------------------------------+\n",
      "| NP           | the Data                              |\n",
      "+--------------+---------------------------------------+\n",
      "| PP           | With John Grinder                     |\n",
      "+--------------+---------------------------------------+\n",
      "| NP           | the neuro-linguistic programming      |\n",
      "+--------------+---------------------------------------+\n",
      "| NP           | NLP                                   |\n",
      "+--------------+---------------------------------------+\n",
      "| NP           | approach                              |\n",
      "+--------------+---------------------------------------+\n",
      "| PP           | in the                                |\n",
      "+--------------+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "table_data = []\n",
    "for sentence in sentences:\n",
    "    parsed_sentence = chunk_text(sentence)\n",
    "    chunks = extract_chunks(parsed_sentence)\n",
    "    # print(parsed_sentence)\n",
    "    if chunks:\n",
    "        table_data.extend(chunks)\n",
    "\n",
    "print(tabulate(table_data, headers=[\"Chunk type\",\"Chunk Phrase\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named entity: Data, Type: ORGANIZATION\n",
      "Named entity: John Grinder, Type: PERSON\n",
      "Named entity: NLP, Type: ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "words  = word_tokenize(test_sentence)\n",
    "tagged_words = nltk.pos_tag(words)\n",
    "named_entities = ne_chunk(tagged_words)\n",
    "for entity in named_entities:\n",
    "    if isinstance(entity, nltk.tree.Tree):\n",
    "        label = entity.label()\n",
    "        phrase = \" \".join(word for word, tag in entity.leaves())\n",
    "        print(f\"Named entity: {phrase}, Type: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "The experiment helps in understanding the use of chunking and how to apply it. I have also learnt how to identify Named Entities in the sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
